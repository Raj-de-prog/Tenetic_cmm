{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "259ec5cd-7156-4cee-9782-49fca3e10edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_location = \"s3://consumer-orbit-us-east-1-holding/Verisk/TCI/*\"\n",
    "df_data = spark.read.option(\"delimiter\", \"\\t\").option(\"inferSchema\", \"False\").csv(file_location, header=False)\n",
    "display(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "214ad6c4-cec3-4e98-a103-4032de2d0376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type #\n",
    "# catalog location : 's3://consumer-orbit-us-east-1-holding/Total_Consumer_Insights_Plus_Counts (5) (1).xlsx'\n",
    "\n",
    "file_location2 = 's3://consumer-orbit-us-east-1-holding/Total_Consumer_Insights_Plus_Counts (5) (1).xlsx'\n",
    "file_type = \"com.crealytics.spark.excel\"\n",
    "\n",
    "Total_Consumer_Insights_Counts_df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"dataAddress\", \"'Sheet1'!A11\") \\\n",
    "  .load(file_location2)\n",
    "\n",
    "# Drop rows where all columns are null\n",
    "Total_Consumer_Insights_Counts_df = Total_Consumer_Insights_Counts_df.dropna(how='all')\n",
    "\n",
    "# Display the schema to find the correct column name\n",
    "Total_Consumer_Insights_Counts_df.printSchema()\n",
    "\n",
    "\n",
    "display(Total_Consumer_Insights_Counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbfd0733-78be-4420-8988-af0ea962940d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Take 'Field Name' column of second file (df2) and use it as header in first file (df1)\n",
    "\n",
    "# Drop rows where 'Field Name' column is null\n",
    "field_name=Total_Consumer_Insights_Counts_df.dropna(subset=['Field Name'])\n",
    "\n",
    "# Select only 'Field Name' column\n",
    "field_name = field_name.select('Field Name')\n",
    "\n",
    "display(field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "053149f6-a706-4f27-9ed0-b9b1c6b1f8f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type \n",
    "# catalog location : 's3://consumer-orbit-us-east-1-holding/Total_Consumer_Insights_Counts (9) - Copy.xlsx'\n",
    "\n",
    "file_location3 = 's3://consumer-orbit-us-east-1-holding/Total_Consumer_Insights_Counts (9) - Copy.xlsx'\n",
    "file_type = \"com.crealytics.spark.excel\"\n",
    "\n",
    "df_Insight_Plus= spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"dataAddress\", \"'Sheet1'!A11\") \\\n",
    "  .load(file_location3)\n",
    "\n",
    "# Drop rows where all columns are null\n",
    "df_Insight_Plus = df_Insight_Plus.dropna(how='all')\n",
    "\n",
    "# Display the schema to find the correct column name\n",
    "df_Insight_Plus.printSchema()\n",
    "\n",
    "\n",
    "display(df_Insight_Plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d77a2b8e-4ba4-4431-9037-dbed9726df20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Take 'Field Name' column of second file (df2) and use it as header in first file (df1)\n",
    "\n",
    "# Drop rows where 'Field Name' column is null\n",
    "field_name2=df_Insight_Plus.dropna(subset=['Field Name'])\n",
    "\n",
    "# Select only 'Field Name' column\n",
    "field_name2 = field_name2.select('Field Name')\n",
    "\n",
    "display(field_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2df338d-56a3-4bc1-8393-6d9405680807",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Append field_name with field_name2 and deduplicate them\n",
    "field_name_combined = field_name.union(field_name2).distinct()\n",
    "\n",
    "display(field_name_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1814c324-430a-48f7-b23b-9cdf81d628d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use combined_field_name as header in df_data\n",
    "combined_field_name_list = [row['Field Name'] for row in field_name_combined.collect()]\n",
    "df_data = df_data.toDF(*combined_field_name_list)\n",
    "display(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd9309cd-721e-4d93-ba20-85bdd8c1a4d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_location4= 's3://consumer-orbit-us-east-1-holding/Alteryx Output Conversion/tci_full_import.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cf353c0-c680-4556-8d42-666d0a5bf7a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_validation = spark.read.format(\"csv\").option(\"header\", \"true\").load(f\"s3:{file_location4}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Match Layout",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
